{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats\n",
    "## Transfer Learning with Inception\n",
    "\n",
    "In order to achieve greater performance than the convnet without significant increase in training time, I now take advantage of the image classification capabilities of Google's [Inception v4](http://arxiv.org/abs/1602.07261), pretrained on ImageNet. Since ImageNet is such a large dataset, this network should be able to detect fairly generic features in our images. Moreover, since Imagenet contains many breeds of cat and dog as classes, it may even have learnt features specific to identifying cats or dogs.\n",
    "\n",
    "I start by computing the bottlenecks (i.e. the penultimate layer activations) for Inception on our images and then use a single layer (i.e. logistic regression) on these computed features to predict the probabilty that a given image contains a dog. Once the bottlenecks are computed and saved to TFRecord files, they can be fed into the network by an input pipeline just like the images themselves were for the convnet. Where `dataset.py` handled the image TFRecords (both reading and writing), `bottleneck.py` handles the bottleneck TFRecords.\n",
    "\n",
    "Unlike some older Inception networks, Google does not provide a ProtoBuf GraphDef file for Inception v4. Instead, Python source files are provided which recreate the network using [TF-Slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim), a high level wrapper for TensorFlow. Also provided, of course, are checkpoint files containing the pretrained weights, biases and other variables. The following files were downloaded from the TF-Slim [models page](https://github.com/tensorflow/models/tree/master/slim#pre-trained-models) in order to recreate the Inception v4 network:\n",
    "\n",
    "* `inception_v4.py`: the main model building file; I modified this slightly for compatibility with Python 3 and the latest TensorFlow (see comments in file for details)\n",
    "* `inception_utils.py`: helper functions needed by `inception_v4.py`\n",
    "* `inception_v4.ckpt`: the model checkpoint\n",
    "\n",
    "Since the bottleneck creation is handled by the `bottleneck.py` script, all that remains to do is train a logistic regression model on the cached bottleneck values. I could use, say, `scikit-learn` for this, providing access to the best routines for training linear models, as well as alternative linear classifiers such as SVMs. However, in the name of simplicity and consistency, I instead treat the linear model as a fully connected network with no hidden layer, so that it can be trained using TensorFlow and my `tfutil` helper functions as in the previous notebook.\n",
    "\n",
    "### Results\n",
    "The results are indeed much better than with the basic convnet.\n",
    "\n",
    "#### Training Summary\n",
    "| learning rate | epoch count |\n",
    "|---------------|-------------|\n",
    "| 1e-4          | 25          |\n",
    "\n",
    "#### Scoring\n",
    "| dataset    | accuracy | loss    |\n",
    "|------------|----------|---------|\n",
    "| train      | 99.6%    | 0.031   |\n",
    "| validation | 99.5%    | 0.033   |\n",
    "| test       | 99.7%    | 0.033   |\n",
    "| kaggle     |          | 0.0733  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import bottleneck\n",
    "import dataset\n",
    "import tfutil as tfu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception expects 299x299 pixel images as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 299)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.image_dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lm(images, reg_terms, train=True, share=False):\n",
    "    with tf.variable_scope('lm', reuse=share):\n",
    "        keep_prob = 0.5 if train else 1.0\n",
    "        h = tf.nn.dropout(images, keep_prob=keep_prob)\n",
    "        h = tfu.fc_op(h, channels_in=bottleneck.FLAGS['BOTTLENECK_SIZE'], channels_out=1, reg_terms=reg_terms, alpha=0.01, name='out', relu=False)\n",
    "        \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NAME = 'inception_lm'\n",
    "lm_reg_terms = {}\n",
    "\n",
    "args = {\n",
    "    'name': NAME,\n",
    "    'inference_op': lm,\n",
    "    'reg_terms': lm_reg_terms,\n",
    "    'inputs': bottleneck.inputs\n",
    "}\n",
    "\n",
    "training_args = {\n",
    "    **args,\n",
    "    'optimizer': tf.train.AdamOptimizer,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfu.run_cleanup(name=NAME)\n",
    "tfu.run_setup(name=NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 50.6%\n",
      "Validation Accuracy: 48.6%\n",
      "Train Loss: 0.729\n",
      "Validation Loss: 0.751\n",
      "Cross Entropy: 0.739\n",
      "Cross Entropy: 0.205\n",
      "Cross Entropy: 0.118\n",
      "Cross Entropy: 0.109\n",
      "Train Accuracy: 98.9%\n",
      "Validation Accuracy: 99.1%\n",
      "Train Loss: 0.068\n",
      "Validation Loss: 0.067\n",
      "Cross Entropy: 0.043\n",
      "Cross Entropy: 0.068\n",
      "Cross Entropy: 0.042\n",
      "Cross Entropy: 0.062\n",
      "Train Accuracy: 99.6%\n",
      "Validation Accuracy: 99.4%\n",
      "Train Loss: 0.051\n",
      "Validation Loss: 0.048\n",
      "Cross Entropy: 0.039\n",
      "Cross Entropy: 0.037\n",
      "Cross Entropy: 0.043\n",
      "Cross Entropy: 0.031\n",
      "Train Accuracy: 99.2%\n",
      "Validation Accuracy: 99.3%\n",
      "Train Loss: 0.038\n",
      "Validation Loss: 0.042\n",
      "Cross Entropy: 0.032\n",
      "Cross Entropy: 0.033\n",
      "Cross Entropy: 0.069\n",
      "Cross Entropy: 0.032\n",
      "Train Accuracy: 99.4%\n",
      "Validation Accuracy: 99.3%\n",
      "Train Loss: 0.041\n",
      "Validation Loss: 0.038\n",
      "Cross Entropy: 0.027\n",
      "Cross Entropy: 0.047\n",
      "Cross Entropy: 0.053\n",
      "Cross Entropy: 0.032\n",
      "Done training for 4930 steps.\n",
      "Train Accuracy: 99.3%\n",
      "Validation Accuracy: 99.4%\n",
      "Train Loss: 0.031\n",
      "Validation Loss: 0.036\n"
     ]
    }
   ],
   "source": [
    "tfu.run_training(\n",
    "    learning_rate=1e-4,\n",
    "    num_epochs=25,\n",
    "    **training_args\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 99.5%\n",
      "Validation Accuracy: 99.3%\n",
      "Test Accuracy: 99.7%\n",
      "Train Loss: 0.037\n",
      "Validation Loss: 0.037\n",
      "Test Loss: 0.033\n"
     ]
    }
   ],
   "source": [
    "tfu.run_eval(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote predictions to ./data/inception_lm_clipped.csv\n",
      "Wrote predictions to ./data/inception_lm.csv\n"
     ]
    }
   ],
   "source": [
    "tfu.run_prediction(**args, clip=True)\n",
    "tfu.run_prediction(**args, clip=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
