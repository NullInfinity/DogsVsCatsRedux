{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnet\n",
    "Now we try adding convolutional layers which hopefully give better performance in the context of image recognition. We follow the principle that we should add more layers as long as our network does not appear to be overfitting (validation error increasing while cross entropy on test batches continues to decrease). However, we also keep things fairly simple to keep computation times down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import dataset\n",
    "import tfutil as tfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original convnet that got ~80% (but now seems to be overfitting). name=conv_2\n",
    "def conv_2_inference_op(images, train=True):\n",
    "    h = tf.reshape(images, [-1,] + list(dataset.image_dim(include_channels=True)))\n",
    "    keep_prob = 0.5 if train else 1.0\n",
    "    \n",
    "    with tf.variable_scope('conv', reuse=(not train)):\n",
    "        h = tfu.conv_op(h, size=40, channels=[3, 16], stride=2, name='conv1')\n",
    "        h = tfu.conv_op(h, size=25, channels=[16, 64], stride=2, name='conv2')\n",
    "        h = tfu.pool_op(h, size=2, stride=2, mode='avg', name='pool1')\n",
    "        # size is now 38 x 38 x 64\n",
    "        h = tfu.conv_op(h, size=16, channels=[64, 128], stride=1, name='conv3')\n",
    "        h = tfu.conv_op(h, size=7, channels=[128, 256], stride=2, name='conv4', padding='VALID')\n",
    "        h = tfu.pool_op(h, size=2, stride=2, mode='max', name='pool2')\n",
    "        \n",
    "        # now size is:\n",
    "        FC_IN_SIZE = 8 * 8 * 256\n",
    "        h = tf.reshape(h, [-1, FC_IN_SIZE])\n",
    "        \n",
    "        h = tfu.fc_op(h, FC_IN_SIZE, 1024, name='fc1')\n",
    "        h = tfu.fc_op(h, 1024, 1024, name='fc2')\n",
    "        h = tf.nn.dropout(h, keep_prob=keep_prob)\n",
    "        \n",
    "        logits = tfu.fc_op(h, 1024, 1, relu=False, name='out')\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_3_inference_op(images, train=True):\n",
    "    h = tf.reshape(images, [-1,] + list(dataset.image_dim(include_channels=True)))\n",
    "    keep_prob = 0.5 if train else 1.0\n",
    "    \n",
    "    with tf.variable_scope('conv', reuse=(not train)):\n",
    "        h = tfu.conv_op(h, size=40, channels=[3, 16], stride=2, name='conv1')\n",
    "        h = tfu.conv_op(h, size=25, channels=[16, 64], stride=2, name='conv2')\n",
    "        h = tfu.pool_op(h, size=2, stride=2, mode='avg', name='pool1')\n",
    "        # size is now 38 x 38 x 64\n",
    "        \n",
    "        h = tfu.conv_op(h, size=16, channels=[64, 128], stride=1, name='conv3')\n",
    "        h = tfu.conv_op(h, size=7, channels=[128, 256], stride=2, name='conv4', padding='VALID')\n",
    "        h = tfu.pool_op(h, size=2, stride=2, mode='max', name='pool2')\n",
    "        # size is now 8 * 8 * 256\n",
    "        \n",
    "        h = tfu.conv_op(h, size=3, channels=[256, 256], stride=1, name='conv5', padding='VALID')\n",
    "        h = tf.nn.dropout(h, keep_prob=keep_prob)\n",
    "        \n",
    "        # now size is:\n",
    "        FC_IN_SIZE = 6 * 6 * 256\n",
    "        h = tf.reshape(h, [-1, FC_IN_SIZE])\n",
    "        \n",
    "        h = tfu.fc_op(h, FC_IN_SIZE, 512, name='fc1')\n",
    "        h = tfu.fc_op(h, 512, 512, name='fc2')\n",
    "        #h = tfu.fc_op(h, 1024, 1024, name='fc3')\n",
    "        h = tf.nn.dropout(h, keep_prob=keep_prob)\n",
    "        \n",
    "        logits = tfu.fc_op(h, 512, 1, relu=False, name='out')\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 49.6%\n",
      "Validation accuracy: 51.7%\n",
      "Cross Entropy: 0.73\n",
      "Cross Entropy: 0.69\n",
      "Cross Entropy: 0.69\n",
      "Cross Entropy: 0.7\n",
      "Train accuracy: 50.0%\n",
      "Validation accuracy: 48.4%\n",
      "Cross Entropy: 0.69\n",
      "Cross Entropy: 0.69\n",
      "Cross Entropy: 0.69\n",
      "Cross Entropy: 0.69\n",
      "Done training for 1972 steps.\n",
      "Validation accuracy: 51.7%\n",
      "Test accuracy: 51.2%\n",
      "Wrote 12500 predictions to ./data/conv_3.csv\n"
     ]
    }
   ],
   "source": [
    "tfu.run_all(\n",
    "    inference_op=conv_3_inference_op,\n",
    "    inputs=dataset.inputs,\n",
    "    total_epochs=5,\n",
    "    learning_rate=1e-4,\n",
    "    name='conv_3',\n",
    "    do_training=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_inference_op(images, train=True):\n",
    "    images = tf.reshape(images, [-1, 299, 299, 3])\n",
    "    keep_prob = 0.5 if train else 1.0\n",
    "    \n",
    "    with tf.variable_scope('conv', reuse=(not train)):\n",
    "        with tf.variable_scope('conv1'):\n",
    "            weights = tfu.normal_weight_variable([40, 40, 3, 16], stddev=sqrt(2./(40*40*3)))\n",
    "            bias = tfu.constant_bias_variable([16])\n",
    "            h_conv = tf.nn.relu(tf.nn.conv2d(images, weights, strides=[1, 2, 2, 1], padding='SAME') + bias)\n",
    "            h_out = h_conv\n",
    "        \n",
    "        with tf.variable_scope('conv2'):\n",
    "            weights = tfu.normal_weight_variable([40, 40, 16, 32], stddev=sqrt(2./(40*40*16)))\n",
    "            bias = tfu.constant_bias_variable([32])\n",
    "            h_conv = tf.nn.relu(tf.nn.conv2d(h_out, weights, strides=[1, 1, 1, 1], padding='SAME') + bias)\n",
    "            h_pool = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1])\n",
    "            h_out = h_pool\n",
    "            \n",
    "        with tf.variable_scope('conv3'):\n",
    "            weights = tfu.normal_weight_variable([15, 15, 32, 128], stddev=sqrt(2./(25*25*64)))\n",
    "            bias = tfu.constant_bias_variable([64])\n",
    "            h_conv = tf.nn.relu(tf.nn.conv2d(h_conv, weights, strides=[1, 2, 2, 1], padding='SAME') + bias)\n",
    "            h_pool = tf.nn.avg_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2 ,2, 1], padding='SAME')\n",
    "            \n",
    "        with tf.variable_scope('conv3'):\n",
    "            weights = tfu.normal_weight_variable([16, 16, 64, 128], stddev=sqrt(2./(16*16*32)))\n",
    "            bias = tfu.constant_bias_variable([128])\n",
    "            h_conv = tf.nn.relu(tf.nn.conv2d(h_pool, weights, strides=[1, 1, 1, 1], padding='VALID') + bias)\n",
    "            h_pool = tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "        FC_IN_SIZE = 5 * 5 * 128\n",
    "        h_in = tf.reshape(h_pool, [-1, FC_IN_SIZE])\n",
    "        \n",
    "        with tf.variable_scope('fc1'):\n",
    "            \n",
    "            weights = tfu.normal_weight_variable([FC_IN_SIZE, 1024], stddev=sqrt(2./FC_IN_SIZE))\n",
    "            bias = tfu.constant_bias_variable([1024])\n",
    "            h_out = tf.nn.relu(tf.matmul(h_in, weights) + bias)\n",
    "            \n",
    "        with tf.name_scope('out'):\n",
    "            weights_out = tfu.normal_weight_variable([1024, 1])\n",
    "            bias_out = tfu.constant_bias_variable([1])\n",
    "            y = tf.matmul(h_out, weights_out) + bias_out\n",
    "    \n",
    "    return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
